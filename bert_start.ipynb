{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_start.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9rfCL8CdIQBO","colab_type":"code","colab":{}},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HyDl35Drt5ar","colab_type":"code","outputId":"8202c8e6-1e5c-4ac9-cbb8-59173d0b0df9","executionInfo":{"status":"ok","timestamp":1587441502049,"user_tz":-420,"elapsed":24305,"user":{"displayName":"Woradanue Nakdee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwlrfLlSfQyqMOfUQQh2MiC3uvkPfTMcJNcsvZCA=s64","userId":"17393324556265428893"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xQtQfkVJuDL4","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/gdrive/My Drive/Colab Notebooks/bert_tf1')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4T_gsT1mwEZN","colab_type":"code","outputId":"7d2627a7-1f7a-44a4-88d8-1791925ed77d","executionInfo":{"status":"ok","timestamp":1587441509048,"user_tz":-420,"elapsed":7634,"user":{"displayName":"Woradanue Nakdee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwlrfLlSfQyqMOfUQQh2MiC3uvkPfTMcJNcsvZCA=s64","userId":"17393324556265428893"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"23iYEhwVCVOf","colab_type":"code","colab":{}},"source":["!python create_pretraining_data.py --input_file=./may.txt --output_file=tmp/may.tfrecord --vocab_file=./model/vocab.txt --do_lower_case=False --max_seq_length=256 --max_predictions_per_seq=20 --masked_lm_prob=0.15 --random_seed=12345 --dupe_factor=5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNQ7CAW1DMLE","colab_type":"code","outputId":"98d0678c-d007-41a3-8df9-7591ee7bff82","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_pretraining.py --input_file=./tmp/may.tfrecord --output_dir=./may_pretrain --do_train=True --do_eval=True --bert_config_file=./model/bert_config.json --init_checkpoint=./model/bert_model.ckpt --train_batch_size=8 --max_seq_length=256 --max_predictions_per_seq=20 --num_train_steps=100000 --num_warmup_steps=1000 --save_checkpoints_steps=50000 --learning_rate=5e-5"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From run_pretraining.py:493: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","W0421 03:58:36.172243 140036935178112 module_wrapper.py:139] From run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","WARNING:tensorflow:From run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n","\n","W0421 03:58:36.172505 140036935178112 module_wrapper.py:139] From run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0421 03:58:36.172742 140036935178112 module_wrapper.py:139] From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W0421 03:58:36.636420 140036935178112 module_wrapper.py:139] From run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","WARNING:tensorflow:From run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","W0421 03:58:36.637048 140036935178112 module_wrapper.py:139] From run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","WARNING:tensorflow:From run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0421 03:58:36.638244 140036935178112 module_wrapper.py:139] From run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:*** Input Files ***\n","I0421 03:58:36.638521 140036935178112 run_pretraining.py:420] *** Input Files ***\n","INFO:tensorflow:  ./tmp/may.tfrecord\n","I0421 03:58:36.638735 140036935178112 run_pretraining.py:422]   ./tmp/may.tfrecord\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","W0421 03:58:36.638957 140036935178112 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","I0421 03:58:37.504888 140036935178112 utils.py:141] NumExpr defaulting to 2 threads.\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5c817b58c8>) includes params argument, but params are not passed to Estimator.\n","W0421 03:58:38.632763 140036935178112 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5c817b58c8>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Using config: {'_model_dir': './may_pretrain', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 50000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5c8175e2b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n","I0421 03:58:38.634173 140036935178112 estimator.py:212] Using config: {'_model_dir': './may_pretrain', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 50000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5c8175e2b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n","INFO:tensorflow:_TPUContext: eval_on_tpu True\n","I0421 03:58:38.634815 140036935178112 tpu_context.py:220] _TPUContext: eval_on_tpu True\n","WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n","W0421 03:58:38.635280 140036935178112 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.\n","INFO:tensorflow:***** Running training *****\n","I0421 03:58:38.635434 140036935178112 run_pretraining.py:459] ***** Running training *****\n","INFO:tensorflow:  Batch size = 8\n","I0421 03:58:38.635577 140036935178112 run_pretraining.py:460]   Batch size = 8\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","W0421 03:58:40.432749 140036935178112 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0421 03:58:40.433275 140036935178112 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:From run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","W0421 03:58:40.444816 140036935178112 module_wrapper.py:139] From run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","WARNING:tensorflow:From run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","W0421 03:58:40.451134 140036935178112 deprecation.py:323] From run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0421 03:58:40.451317 140036935178112 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","W0421 03:58:40.475018 140036935178112 deprecation.py:323] From run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n","W0421 03:58:40.475210 140036935178112 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n","WARNING:tensorflow:Entity <function input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f5c80425c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n","W0421 03:58:40.489351 140036935178112 ag_logging.py:146] Entity <function input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f5c80425c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n","WARNING:tensorflow:From run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n","\n","W0421 03:58:40.489573 140036935178112 module_wrapper.py:139] From run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n","\n","WARNING:tensorflow:From run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0421 03:58:40.501576 140036935178112 deprecation.py:323] From run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Calling model_fn.\n","I0421 03:58:40.530306 140036935178112 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Running train on CPU\n","I0421 03:58:40.530514 140036935178112 tpu_estimator.py:3124] Running train on CPU\n","INFO:tensorflow:*** Features ***\n","I0421 03:58:40.530873 140036935178112 run_pretraining.py:117] *** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (8, 256)\n","I0421 03:58:40.531115 140036935178112 run_pretraining.py:119]   name = input_ids, shape = (8, 256)\n","INFO:tensorflow:  name = input_mask, shape = (8, 256)\n","I0421 03:58:40.531336 140036935178112 run_pretraining.py:119]   name = input_mask, shape = (8, 256)\n","INFO:tensorflow:  name = masked_lm_ids, shape = (8, 20)\n","I0421 03:58:40.531489 140036935178112 run_pretraining.py:119]   name = masked_lm_ids, shape = (8, 20)\n","INFO:tensorflow:  name = masked_lm_positions, shape = (8, 20)\n","I0421 03:58:40.531639 140036935178112 run_pretraining.py:119]   name = masked_lm_positions, shape = (8, 20)\n","INFO:tensorflow:  name = masked_lm_weights, shape = (8, 20)\n","I0421 03:58:40.531787 140036935178112 run_pretraining.py:119]   name = masked_lm_weights, shape = (8, 20)\n","INFO:tensorflow:  name = next_sentence_labels, shape = (8, 1)\n","I0421 03:58:40.531928 140036935178112 run_pretraining.py:119]   name = next_sentence_labels, shape = (8, 1)\n","INFO:tensorflow:  name = segment_ids, shape = (8, 256)\n","I0421 03:58:40.532088 140036935178112 run_pretraining.py:119]   name = segment_ids, shape = (8, 256)\n","WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0421 03:58:40.532354 140036935178112 module_wrapper.py:139] From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","W0421 03:58:40.533861 140036935178112 module_wrapper.py:139] From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n","W0421 03:58:40.557237 140036935178112 module_wrapper.py:139] From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0421 03:58:40.594109 140036935178112 deprecation.py:506] From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","W0421 03:58:40.608958 140036935178112 deprecation.py:323] From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0421 03:58:40.610228 140036935178112 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From run_pretraining.py:150: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","W0421 03:58:42.855683 140036935178112 module_wrapper.py:139] From run_pretraining.py:150: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","WARNING:tensorflow:From run_pretraining.py:165: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n","\n","W0421 03:58:43.684372 140036935178112 module_wrapper.py:139] From run_pretraining.py:165: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n","\n","INFO:tensorflow:**** Trainable Variables ****\n","I0421 03:58:44.359371 140036935178112 run_pretraining.py:167] **** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (119547, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.359664 140036935178112 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (119547, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.359846 140036935178112 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.360023 140036935178112 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.360189 140036935178112 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.360334 140036935178112 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.360476 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.360623 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.360774 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.360923 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.361081 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.361241 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.361377 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.361519 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.361656 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.361806 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","I0421 03:58:44.361941 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","I0421 03:58:44.362099 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.362241 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.362411 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.362552 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.362718 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.362854 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.363010 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.363151 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.363291 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.363495 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.363708 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.363870 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.364076 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.364239 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.364429 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","I0421 03:58:44.364554 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","I0421 03:58:44.364694 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.364868 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.365072 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.365248 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.365399 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.365531 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.365720 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.365890 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.366097 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.366255 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.366406 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.366581 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.366716 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.366907 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.367056 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","I0421 03:58:44.367212 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","I0421 03:58:44.367366 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.367545 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.367751 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.367906 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.368069 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.368208 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.368347 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.368578 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.368765 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.368940 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.369098 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.369273 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.369431 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.369567 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.369714 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","I0421 03:58:44.369916 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","I0421 03:58:44.370116 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.444643 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.444818 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.445022 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.445251 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.445452 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.445664 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.445879 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.446091 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.446298 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.446566 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.446826 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.447062 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.447242 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.447456 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","I0421 03:58:44.447660 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","I0421 03:58:44.447844 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.448148 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.448338 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.448611 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.448764 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.448930 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.449162 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.449345 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.449544 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.449718 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.449904 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.450108 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.450317 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.450484 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.450663 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","I0421 03:58:44.450824 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","I0421 03:58:44.451034 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.451217 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.451461 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.451673 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.451845 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.452094 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.452378 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.452573 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.452805 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.453102 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.453359 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.453640 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.453892 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.454150 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.454376 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","I0421 03:58:44.454627 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","I0421 03:58:44.454841 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.455084 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.455333 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.455556 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.455755 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.455969 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.456188 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.456379 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.456556 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.456805 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.457067 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.457248 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.457428 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.457611 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.457784 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","I0421 03:58:44.457954 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","I0421 03:58:44.458170 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.458347 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.458601 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.458814 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.458972 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.459172 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.459350 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.459512 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.459674 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.459845 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.460067 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.460265 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.461282 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.461478 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.461937 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","I0421 03:58:44.462157 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","I0421 03:58:44.462360 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.462592 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.462870 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.463098 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.463273 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.463524 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.463738 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.463903 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.464124 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.464284 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.464490 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.464688 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.464881 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.465115 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.465270 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","I0421 03:58:44.465420 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","I0421 03:58:44.465582 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.465743 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.465905 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.466111 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.466305 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.466541 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.466802 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.466969 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.467229 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.467381 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.467578 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.467757 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.467909 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.468076 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.468214 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","I0421 03:58:44.468348 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","I0421 03:58:44.468501 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.468659 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.468853 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.469102 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.469247 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.469380 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.469538 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.469756 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.469915 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.470076 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.470220 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.470355 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.470585 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.470781 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.470952 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","I0421 03:58:44.471165 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","I0421 03:58:44.471342 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.471482 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.471650 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.471788 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.471929 140036935178112 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.472102 140036935178112 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.472292 140036935178112 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.472473 140036935178112 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.472653 140036935178112 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.472820 140036935178112 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","I0421 03:58:44.473007 140036935178112 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (119547,), *INIT_FROM_CKPT*\n","I0421 03:58:44.473177 140036935178112 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (119547,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n","I0421 03:58:44.473323 140036935178112 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n","I0421 03:58:44.473497 140036935178112 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n","WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0421 03:58:44.473724 140036935178112 module_wrapper.py:139] From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n","W0421 03:58:44.562938 140036935178112 module_wrapper.py:139] From /content/gdrive/My Drive/Colab Notebooks/bert_tf1/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0421 03:58:44.830616 140036935178112 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","INFO:tensorflow:Done calling model_fn.\n","I0421 03:58:52.009872 140036935178112 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I0421 03:58:52.011624 140036935178112 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I0421 03:58:55.168703 140036935178112 monitored_session.py:240] Graph was finalized.\n","2020-04-21 03:58:55.181792: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-04-21 03:58:55.182175: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2580bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-04-21 03:58:55.182212: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-04-21 03:58:55.187925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-04-21 03:58:55.326322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-21 03:58:55.327192: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2581640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-04-21 03:58:55.327223: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2020-04-21 03:58:55.328631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-21 03:58:55.329309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-04-21 03:58:55.329653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-21 03:58:55.331307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-21 03:58:55.332867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-21 03:58:55.333207: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-21 03:58:55.334956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-21 03:58:55.357528: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-21 03:58:55.360937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-21 03:58:55.361114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-21 03:58:55.361875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-21 03:58:55.362531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-21 03:58:55.365832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-21 03:58:55.367528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-21 03:58:55.367574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-21 03:58:55.367590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-21 03:58:55.369113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-21 03:58:55.369838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-21 03:58:55.370483: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-04-21 03:58:55.370531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","INFO:tensorflow:Restoring parameters from ./may_pretrain/model.ckpt-0\n","I0421 03:58:55.374864 140036935178112 saver.py:1284] Restoring parameters from ./may_pretrain/model.ckpt-0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I7l3eQQJyATO","colab_type":"code","colab":{}},"source":["!python run_classifier.py --task_name=cola --do_train=true --do_eval=true --data_dir=./data/ --vocab_file=./model/vocab.txt --bert_config_file=./model/bert_config.json --init_checkpoint=./may_pretrain/model.ckpt-50000 --max_seq_length=256 --train_batch_size=8 --learning_rate=5e-5 --num_train_epochs=3.0 --save_checkpoints_steps=4000 --output_dir=./output/ --do_lower_case=False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v11NjijiSnTs","colab_type":"code","colab":{}},"source":["!python run_classifier.py --task_name=cola --do_predict=true --data_dir=./data/ --vocab_file=./model/vocab.txt --bert_config_file=./model/bert_config.json --init_checkpoint=./output/model.ckpt-6000 --max_seq_length=128 --output_dir=./output/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dQbonlRcKVH3","colab_type":"text"},"source":["prediction result, test_results.tsv,  is in output folder"]},{"cell_type":"code","metadata":{"id":"UWqn3YTkVWwA","colab_type":"code","outputId":"d66fab4d-62ec-49f8-99a2-537f81e57e4a","executionInfo":{"status":"ok","timestamp":1587098325954,"user_tz":-420,"elapsed":1034,"user":{"displayName":"Woradanue Nakdee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwlrfLlSfQyqMOfUQQh2MiC3uvkPfTMcJNcsvZCA=s64","userId":"17393324556265428893"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["import pandas as pd\n","df_result = pd.read_csv('output/test_results.tsv', sep='\\t', header=None)\n","df_result.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.135338</td>\n","      <td>0.085037</td>\n","      <td>0.779625</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.235957</td>\n","      <td>0.053379</td>\n","      <td>0.710664</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.140682</td>\n","      <td>0.082294</td>\n","      <td>0.777023</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.329745</td>\n","      <td>0.068317</td>\n","      <td>0.601938</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.197637</td>\n","      <td>0.234928</td>\n","      <td>0.567436</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1         2\n","0  0.135338  0.085037  0.779625\n","1  0.235957  0.053379  0.710664\n","2  0.140682  0.082294  0.777023\n","3  0.329745  0.068317  0.601938\n","4  0.197637  0.234928  0.567436"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"XjCr0bctViLU","colab_type":"code","colab":{}},"source":["df_test_with_label = pd.read_csv('data/test_2.tsv', sep='\\t')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qGtJpXI_tDoR","colab_type":"code","colab":{}},"source":["#df_test_with_label = pd.read_csv('data/test.tsv', sep='\\t')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tomDT6XoVi5E","colab_type":"code","outputId":"bd4412b9-3850-4504-96ac-0fb4db83cf80","executionInfo":{"status":"ok","timestamp":1587098330869,"user_tz":-420,"elapsed":1022,"user":{"displayName":"Woradanue Nakdee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwlrfLlSfQyqMOfUQQh2MiC3uvkPfTMcJNcsvZCA=s64","userId":"17393324556265428893"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df_predict = pd.DataFrame({'id':df_test_with_label['id'],\n","                            'labels':df_result.idxmax(axis=1),\n","                            'text':df_test_with_label['text_clean'],})\n","df_predict.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>labels</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>09FAF362B7</td>\n","      <td>2</td>\n","      <td>เรื่องเซ็งๆ อยู่ๆ ไฟผ่าหมาก  ก็กระพริบเอง จนแบ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>D51CB3AF19</td>\n","      <td>2</td>\n","      <td>โอ้ยอยากอะ แต่ไม่มีชุดไทย</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8C2C43850E</td>\n","      <td>2</td>\n","      <td>โตโยต้า วุ่นวายอยู่กับการพัฒนารถพลังงานไฮไดรเย...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>048E2FBEE7</td>\n","      <td>2</td>\n","      <td>บ่ายนี้ไปจัดสะเลย</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5E22583DCD</td>\n","      <td>2</td>\n","      <td>ปกติกินประจำมาก ต่อบัตรสมาชิกมา  ปีละ เจอตุ่มเ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           id  labels                                               text\n","0  09FAF362B7       2  เรื่องเซ็งๆ อยู่ๆ ไฟผ่าหมาก  ก็กระพริบเอง จนแบ...\n","1  D51CB3AF19       2                          โอ้ยอยากอะ แต่ไม่มีชุดไทย\n","2  8C2C43850E       2  โตโยต้า วุ่นวายอยู่กับการพัฒนารถพลังงานไฮไดรเย...\n","3  048E2FBEE7       2                                  บ่ายนี้ไปจัดสะเลย\n","4  5E22583DCD       2  ปกติกินประจำมาก ต่อบัตรสมาชิกมา  ปีละ เจอตุ่มเ..."]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"osP4B9yjV1fG","colab_type":"code","colab":{}},"source":["df_predict.to_csv('data/df_predict.csv',index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TxwLCK2pWZPV","colab_type":"code","colab":{}},"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i779GNOedJ66","colab_type":"code","colab":{}},"source":["y_labels = df_test_with_label['labels']\n","y_predict = df_predict['labels']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rhDxi1-zd8wI","colab_type":"code","outputId":"e73ac96e-26af-4c31-acbe-472ab0346a0b","executionInfo":{"status":"ok","timestamp":1587098351389,"user_tz":-420,"elapsed":1083,"user":{"displayName":"Woradanue Nakdee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwlrfLlSfQyqMOfUQQh2MiC3uvkPfTMcJNcsvZCA=s64","userId":"17393324556265428893"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["accuracy = accuracy_score(y_labels, y_predict)\n","print('Accuracy: %f' % accuracy)\n","\n","precision = precision_score(y_labels, y_predict, average='macro')\n","print('Precision: %f' % precision)\n","\n","recall = recall_score(y_labels, y_predict, average='macro')\n","print('Recall: %f' % recall)\n","\n","f1 = f1_score(y_labels, y_predict, average='macro')\n","print('F1 score: %f' % f1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy: 0.626804\n","Precision: 0.423292\n","Recall: 0.468435\n","F1 score: 0.434048\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"j9jEDxibeTIU","colab_type":"code","outputId":"7a3bf6e9-8972-4b7b-ca78-c4b9636b6bc5","executionInfo":{"status":"ok","timestamp":1587098365791,"user_tz":-420,"elapsed":1391,"user":{"displayName":"Woradanue Nakdee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwlrfLlSfQyqMOfUQQh2MiC3uvkPfTMcJNcsvZCA=s64","userId":"17393324556265428893"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["cm = confusion_matrix(y_labels, y_predict)\n","print(cm)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[   0  104  898]\n"," [   0  713  707]\n"," [   0  282 2631]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rnrqs3SfeUC9","colab_type":"code","outputId":"5ea1562c-821f-487d-d6c1-646c777e5c1f","executionInfo":{"status":"ok","timestamp":1587098369984,"user_tz":-420,"elapsed":1295,"user":{"displayName":"Woradanue Nakdee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwlrfLlSfQyqMOfUQQh2MiC3uvkPfTMcJNcsvZCA=s64","userId":"17393324556265428893"}},"colab":{"base_uri":"https://localhost:8080/","height":349}},"source":["import seaborn as sns\n","import matplotlib.pyplot as plt \n","%matplotlib inline\n","import numpy as np\n","\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax, fmt='g', cmap='Greens'); #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels'); ax.set_ylabel('True labels'); \n","ax.set_title('Confusion Matrix'); \n","ax.xaxis.set_ticklabels(['pos', 'neg', 'neu']); \n","ax.yaxis.set_ticklabels(['pos', 'neg', 'neu']);"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qozbNe-KehYy","colab_type":"code","outputId":"3ccc4596-e16d-47c6-8d92-0ee098c8ce99","executionInfo":{"status":"ok","timestamp":1587098373401,"user_tz":-420,"elapsed":1296,"user":{"displayName":"Woradanue Nakdee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwlrfLlSfQyqMOfUQQh2MiC3uvkPfTMcJNcsvZCA=s64","userId":"17393324556265428893"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["# Normalized\n","cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","cmn = np.around(cmn, decimals=2)\n","ax = plt.subplot()\n","sns.heatmap(cmn, annot=True, ax = ax, fmt='g', cmap='Blues'); #annot=True to annotate cells\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels'); ax.set_ylabel('True labels'); \n","ax.set_title('Normalized Confusion Matrix'); \n","ax.xaxis.set_ticklabels(['pos', 'neg', 'neu']); \n","ax.yaxis.set_ticklabels(['pos', 'neg', 'neu']);"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}